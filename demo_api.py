"""
Fashion JSON Encoder API Demo Script
Requirements 13: JSON Encoder ë…ë¦½ ê²€ì¦ ë° API í…ŒìŠ¤íŠ¸
"""

import asyncio
import aiohttp
import json
import time
from pathlib import Path
import torch
import torch.nn.functional as F
from PIL import Image
import io

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from models.json_encoder import JSONEncoder
from data.dataset_loader import KFashionDatasetLoader
from utils.validators import InputValidator, ModelValidator

async def test_api_endpoints():
    """API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    base_url = "http://localhost:8000"
    
    async with aiohttp.ClientSession() as session:
        # 1. í—¬ìŠ¤ ì²´í¬
        print("ğŸ” API í—¬ìŠ¤ ì²´í¬...")
        async with session.get(f"{base_url}/health") as response:
            health_data = await response.json()
            print(f"âœ… ì„œë²„ ìƒíƒœ: {health_data['status']}")
            print(f"ğŸ“Š ëª¨ë¸ ë¡œë“œ ìƒíƒœ: {health_data['models_loaded']}")
        
        # 2. JSON ìŠ¤íƒ€ì¼ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        print("\nğŸ¨ JSON ìŠ¤íƒ€ì¼ ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
        style_request = {
            "input_type": "json",
            "style_description": {
                "category": "ìƒì˜",
                "style": ["ë ˆíŠ¸ë¡œ", "ìºì£¼ì–¼"],
                "silhouette": "ì˜¤ë²„ì‚¬ì´ì¦ˆ",
                "material": ["ë‹ˆíŠ¸", "í´ë¦¬ì—ìŠ¤í„°"],
                "detail": ["ë¼ìš´ë“œë„¥", "ê¸´ì†Œë§¤"]
            },
            "options": {
                "top_k": 5,
                "similarity_threshold": 0.1
            }
        }
        
        async with session.post(
            f"{base_url}/api/recommend/style",
            json=style_request
        ) as response:
            if response.status == 200:
                result = await response.json()
                print(f"âœ… ì¶”ì²œ ì„±ê³µ: {len(result['recommendations'])}ê°œ ì•„ì´í…œ")
                print(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {result['performance_metrics']['total_response_time_ms']:.1f}ms")
                
                # ì²« ë²ˆì§¸ ì¶”ì²œ ì•„ì´í…œ ì¶œë ¥
                if result['recommendations']:
                    first_item = result['recommendations'][0]
                    print(f"ğŸ† ìµœê³  ìœ ì‚¬ë„ ì•„ì´í…œ: {first_item['item_id']} (ìœ ì‚¬ë„: {first_item['similarity_score']:.4f})")
            else:
                error_data = await response.json()
                print(f"âŒ ì¶”ì²œ ì‹¤íŒ¨: {error_data}")
        
        # 3. KPI ëŒ€ì‹œë³´ë“œ ë°ì´í„° í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š KPI ëŒ€ì‹œë³´ë“œ ë°ì´í„° í…ŒìŠ¤íŠ¸...")
        async with session.get(f"{base_url}/api/dashboard/kpi") as response:
            if response.status == 200:
                kpi_data = await response.json()
                print(f"âœ… KPI ë°ì´í„° ì¡°íšŒ ì„±ê³µ")
                print(f"ğŸ“ˆ Top-5 ì •í™•ë„: {kpi_data['kpi_cards']['performance_metrics']['top_5_accuracy']:.4f}")
                print(f"ğŸ¯ MRR: {kpi_data['kpi_cards']['performance_metrics']['mrr']:.4f}")
                print(f"ğŸ”„ API ìš”ì²­/ì´ˆ: {kpi_data['api_metrics']['requests_per_second']}")
            else:
                print(f"âŒ KPI ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")

def test_json_encoder_sanity_check():
    """
    JSON Encoder Standalone Sanity Check
    Requirements 13: JSON Encoder ë…ë¦½ ê²€ì¦
    """
    print("\nğŸ§ª JSON Encoder Sanity Check ì‹œì‘...")
    
    try:
        # 1. í•©ì„± ë°ì´í„° ìƒì„±
        print("ğŸ“ í•©ì„± ë°ì´í„° ìƒì„±...")
        synthetic_batch = create_synthetic_json_batch()
        
        # 2. JSON Encoder ì´ˆê¸°í™”
        print("ğŸ—ï¸ JSON Encoder ì´ˆê¸°í™”...")
        vocab_sizes = {
            'category': 10,
            'style': 50,
            'silhouette': 20,
            'material': 30,
            'detail': 40
        }
        
        json_encoder = JSONEncoder(
            vocab_sizes=vocab_sizes,
            embedding_dim=128,
            hidden_dim=256
        )
        json_encoder.eval()
        
        # 3. ì¶œë ¥ ì°¨ì› ê²€ì¦
        print("ğŸ” ì¶œë ¥ ì°¨ì› ê²€ì¦...")
        with torch.no_grad():
            output = json_encoder(synthetic_batch)
        
        ModelValidator.validate_output_dimension(output, expected_dim=512)
        print(f"âœ… ì¶œë ¥ ì°¨ì›: {output.shape} (ì˜ˆìƒ: [ë°°ì¹˜í¬ê¸°, 512])")
        
        # 4. L2 ì •ê·œí™” ê²€ì¦
        print("ğŸ“ L2 ì •ê·œí™” ê²€ì¦...")
        ModelValidator.validate_normalization(output)
        norms = torch.norm(output, dim=-1)
        print(f"âœ… L2 ì •ê·œí™”: í‰ê·  norm = {norms.mean():.6f} (ì˜ˆìƒ: 1.000000)")
        
        # 5. ë°°ì¹˜ ì¼ê´€ì„± ê²€ì¦
        print("ğŸ”„ ë°°ì¹˜ ì¼ê´€ì„± ê²€ì¦...")
        with torch.no_grad():
            output2 = json_encoder(synthetic_batch)
        
        if torch.allclose(output, output2, atol=1e-6):
            print("âœ… ë°°ì¹˜ ì¼ê´€ì„±: ë™ì¼ ì…ë ¥ì— ëŒ€í•´ ë™ì¼ ì¶œë ¥ ìƒì„±")
        else:
            raise ValueError("ë°°ì¹˜ ì¼ê´€ì„± ì‹¤íŒ¨: ë™ì¼ ì…ë ¥ì— ëŒ€í•´ ë‹¤ë¥¸ ì¶œë ¥ ìƒì„±")
        
        # 6. ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ê²€ì¦
        print("âš¡ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ê²€ì¦...")
        json_encoder.train()
        output = json_encoder(synthetic_batch)
        loss = output.sum()  # ë”ë¯¸ ì†ì‹¤
        loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        has_gradients = any(param.grad is not None for param in json_encoder.parameters())
        if has_gradients:
            print("âœ… ê·¸ë˜ë””ì–¸íŠ¸ íë¦„: ì •ìƒì ì¸ ì—­ì „íŒŒ í™•ì¸")
        else:
            raise ValueError("ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ì‹¤íŒ¨: ì—­ì „íŒŒ ì¤‘ ê·¸ë˜ë””ì–¸íŠ¸ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        
        # 7. í•„ë“œ ì²˜ë¦¬ ê²€ì¦
        print("ğŸ·ï¸ í•„ë“œ ì²˜ë¦¬ ê²€ì¦...")
        validate_field_processing(json_encoder, synthetic_batch)
        
        # 8. ìµœì¢… ê²€ì¦ ì™„ë£Œ
        print("\nğŸ‰ **SANITY CHECK PASS** ğŸ‰")
        print("âœ… ëª¨ë“  ê²€ì¦ í•­ëª© í†µê³¼:")
        print("   - 512ì°¨ì› ì¶œë ¥ âœ“")
        print("   - L2 ì •ê·œí™” âœ“")
        print("   - ë°°ì¹˜ ì¼ê´€ì„± âœ“")
        print("   - ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ âœ“")
        print("   - í•„ë“œ ì²˜ë¦¬ âœ“")
        
        # ê²€ì¦ ê²°ê³¼ ì €ì¥
        save_sanity_check_results({
            "status": "PASS",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "output_shape": list(output.shape),
            "l2_norm_mean": norms.mean().item(),
            "l2_norm_std": norms.std().item(),
            "gradient_flow": has_gradients,
            "batch_consistency": True
        })
        
        return True
        
    except Exception as e:
        print(f"\nâŒ **SANITY CHECK FAILED** âŒ")
        print(f"ì˜¤ë¥˜: {str(e)}")
        
        # ì‹¤íŒ¨ ê²°ê³¼ ì €ì¥
        save_sanity_check_results({
            "status": "FAILED",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "error": str(e)
        })
        
        return False

def create_synthetic_json_batch(batch_size: int = 4) -> dict:
    """í•©ì„± JSON ë°°ì¹˜ ë°ì´í„° ìƒì„±"""
    return {
        'category': torch.randint(1, 10, (batch_size,)),
        'style': torch.randint(1, 50, (batch_size, 4)),
        'silhouette': torch.randint(1, 20, (batch_size,)),
        'material': torch.randint(1, 30, (batch_size, 3)),
        'detail': torch.randint(1, 40, (batch_size, 5)),
        'style_mask': torch.ones(batch_size, 4, dtype=torch.long),
        'material_mask': torch.ones(batch_size, 3, dtype=torch.long),
        'detail_mask': torch.ones(batch_size, 5, dtype=torch.long)
    }

def validate_field_processing(json_encoder: JSONEncoder, batch: dict):
    """í•„ë“œ ì²˜ë¦¬ ë¡œì§ ê²€ì¦"""
    # ë‹¨ì¼ ë²”ì£¼í˜• í•„ë“œ í…ŒìŠ¤íŠ¸
    single_cat_batch = {
        'category': torch.tensor([1]),
        'style': torch.tensor([[0, 0, 0, 0]]),  # ëª¨ë“  íŒ¨ë”©
        'silhouette': torch.tensor([5]),
        'material': torch.tensor([[0, 0, 0]]),  # ëª¨ë“  íŒ¨ë”©
        'detail': torch.tensor([[0, 0, 0, 0, 0]]),  # ëª¨ë“  íŒ¨ë”©
        'style_mask': torch.zeros(1, 4, dtype=torch.long),
        'material_mask': torch.zeros(1, 3, dtype=torch.long),
        'detail_mask': torch.zeros(1, 5, dtype=torch.long)
    }
    
    with torch.no_grad():
        output = json_encoder(single_cat_batch)
    
    if output.shape == (1, 512):
        print("âœ… ë‹¨ì¼ ë²”ì£¼í˜• í•„ë“œ ì²˜ë¦¬: ì •ìƒ")
    else:
        raise ValueError(f"ë‹¨ì¼ ë²”ì£¼í˜• í•„ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: ì˜ˆìƒ (1, 512), ì‹¤ì œ {output.shape}")
    
    # ë‹¤ì¤‘ ë²”ì£¼í˜• í•„ë“œ í…ŒìŠ¤íŠ¸
    multi_cat_batch = {
        'category': torch.tensor([1]),
        'style': torch.tensor([[1, 2, 3, 0]]),  # 3ê°œ ìœ íš¨, 1ê°œ íŒ¨ë”©
        'silhouette': torch.tensor([5]),
        'material': torch.tensor([[1, 2, 0]]),  # 2ê°œ ìœ íš¨, 1ê°œ íŒ¨ë”©
        'detail': torch.tensor([[1, 2, 3, 4, 5]]),  # ëª¨ë‘ ìœ íš¨
        'style_mask': torch.tensor([[1, 1, 1, 0]], dtype=torch.long),
        'material_mask': torch.tensor([[1, 1, 0]], dtype=torch.long),
        'detail_mask': torch.ones(1, 5, dtype=torch.long)
    }
    
    with torch.no_grad():
        output = json_encoder(multi_cat_batch)
    
    if output.shape == (1, 512):
        print("âœ… ë‹¤ì¤‘ ë²”ì£¼í˜• í•„ë“œ ì²˜ë¦¬: ì •ìƒ")
    else:
        raise ValueError(f"ë‹¤ì¤‘ ë²”ì£¼í˜• í•„ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: ì˜ˆìƒ (1, 512), ì‹¤ì œ {output.shape}")

def save_sanity_check_results(results: dict):
    """Sanity Check ê²°ê³¼ ì €ì¥"""
    Path("temp_logs").mkdir(exist_ok=True)
    
    with open("temp_logs/sanity_check_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ ê²€ì¦ ê²°ê³¼ ì €ì¥: temp_logs/sanity_check_results.json")

def test_data_loading():
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“‚ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸...")
    
    try:
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        dataset_loader = KFashionDatasetLoader(
            dataset_path="C:/sample/ë¼ë²¨ë§ë°ì´í„°",
            target_categories=['ë ˆíŠ¸ë¡œ', 'ë¡œë§¨í‹±', 'ë¦¬ì¡°íŠ¸']
        )
        
        # ë°ì´í„° ë¡œë“œ
        fashion_items = dataset_loader.load_dataset_by_category()
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(fashion_items)}ê°œ ì•„ì´í…œ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ì¶œë ¥
        category_counts = {}
        for item in fashion_items:
            category_counts[item.category] = category_counts.get(item.category, 0) + 1
        
        print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for category, count in category_counts.items():
            print(f"   - {category}: {count}ê°œ")
        
        # ì–´íœ˜ êµ¬ì¶•
        vocabularies = dataset_loader.build_vocabularies()
        print(f"ğŸ“š ì–´íœ˜ êµ¬ì¶• ì™„ë£Œ: {len(vocabularies)}ê°œ í•„ë“œ")
        
        for field, vocab in vocabularies.items():
            print(f"   - {field}: {len(vocab)}ê°œ í† í°")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return False

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Fashion JSON Encoder API ë°ëª¨ ì‹œì‘")
    print("=" * 50)
    
    # 1. JSON Encoder Sanity Check
    sanity_check_passed = test_json_encoder_sanity_check()
    
    # 2. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
    data_loading_passed = test_data_loading()
    
    # 3. API í…ŒìŠ¤íŠ¸ (ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°)
    print("\nğŸŒ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸...")
    try:
        await test_api_endpoints()
        api_test_passed = True
    except Exception as e:
        print(f"âš ï¸ API í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ): {str(e)}")
        api_test_passed = False
    
    # 4. ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 50)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    print(f"   ğŸ§ª JSON Encoder Sanity Check: {'âœ… PASS' if sanity_check_passed else 'âŒ FAIL'}")
    print(f"   ğŸ“‚ ë°ì´í„° ë¡œë”©: {'âœ… PASS' if data_loading_passed else 'âŒ FAIL'}")
    print(f"   ğŸŒ API í…ŒìŠ¤íŠ¸: {'âœ… PASS' if api_test_passed else 'âš ï¸ SKIP'}")
    
    if sanity_check_passed and data_loading_passed:
        print("\nğŸ‰ ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ! ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    asyncio.run(main())