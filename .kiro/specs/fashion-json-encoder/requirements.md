# 요구사항 문서

## 소개

패션 이미지 추천 시스템 연구 프로젝트를 위한 JSON Encoder 구현. K-fashion 데이터셋의 JSON 메타데이터를 학습하여 FashionCLIP 이미지 임베딩과 정렬되는 512차원 Attribute Embedding을 생성한다.

## 프로젝트 목표

- **주요 목표**: K-Fashion 데이터셋 기반으로 JSON ↔ 이미지 유사도 검색 시스템 구축
- **현재 상태**: 2,172개 아이템으로 초기 학습 완료 (15 에포크)
- **향후 계획**: 추가 학습을 통한 성능 향상 및 실용적 검색 시스템 구축

## 데이터 스코프

- **데이터셋**: K-Fashion 데이터셋 (전체 64GB)
- **학습 대상 카테고리**: 레트로(196개), 로맨틱(994개), 리조트(998개) - 총 2,172개 아이템
- **데이터 구조**: C:/sample/라벨링데이터/{카테고리}/{파일번호}.json 형식
- **학습/검증 분할**: 80% / 20% (학습: 1,737개, 검증: 435개)
- **목표**: 이미지 ↔ JSON 멀티모달 임베딩 공간 정렬

## 전처리 요구사항

- **Polygon to BBox 변환**: 모든 polygon 어노테이션을 bounding box로 변환 필수
- **이미지 크롭**: BBox 기준으로 crop된 이미지 생성
- **BBox 없는 이미지**: 학습 데이터에서 제외
- **학습 단위**: (단일 의류 item crop 이미지, 해당 item의 JSON 메타데이터) 쌍

## JSON 입력 스키마 가정

JSON_Encoder는 전처리된 JSON을 입력으로 받으며, 각 필드는 다음과 같은 타입을 가진다:

- **category**: string (단일 값)
- **style**: list[string]
- **silhouette**: string (단일 값)
- **material**: list[string]
- **detail**: list[string]

모든 필드는 사전에 정의된 vocabulary index로 변환된 상태로 입력된다:

- **단일 범주형 필드**: embedding lookup 방식 사용
- **다중 범주형 필드**: 다중 범주형 필드는 embedding lookup 후 mean pooling 방식으로 집계한다

## 학습 목표

- **임베딩 공간 정렬**: 이미지 임베딩 ↔ JSON 임베딩 공간 정렬
- **손실 함수**: InfoNCE Loss 고정 사용
- **학습 방식**: Contrastive Learning (In-batch negative sampling)

## 출력물

- **JSON Encoder**: PyTorch 기반 신경망 모델
- **Image Encoder**: FashionCLIP 기반 (frozen 상태 유지)
- **공통 임베딩**: 512차원 벡터 공간

## 용어집

- **JSON_Encoder**: JSON 메타데이터를 512차원 벡터로 변환하는 신경망 모델
- **FashionCLIP_Image_Encoder**: 이미지를 512차원 벡터로 변환하는 사전 훈련된 모델 (학습 대상 아님)
- **Attribute_Embedding**: JSON Encoder가 출력하는 512차원 벡터
- **K_Fashion_Dataset**: 패션 이미지와 JSON 메타데이터 쌍으로 구성된 데이터셋
- **Contrastive_Learning**: positive/negative 쌍을 이용한 학습 방식

## 요구사항

### 요구사항 1

**사용자 스토리:** 연구자로서, JSON 메타데이터를 512차원 벡터로 변환하고 싶다, 이미지 임베딩과 비교 가능한 공간에서 작업하기 위해서.

#### 승인 기준

1. WHEN JSON 메타데이터가 입력되면, THE JSON_Encoder SHALL 정확히 512차원 벡터를 출력한다
2. WHEN 출력 벡터가 생성되면, THE JSON_Encoder SHALL FashionCLIP 이미지 임베딩과 cosine similarity 계산이 가능한 형태로 출력한다
3. THE JSON_Encoder SHALL PyTorch Module로 구현된다
4. THE JSON_Encoder SHALL Embedding과 MLP만을 사용한 단순한 구조로 구성된다
5. THE FashionCLIP_Image_Encoder SHALL NOT be updated or fine-tuned during training


### 요구사항 2

**사용자 스토리:** 연구자로서, 다양한 패션 속성을 처리하고 싶다, 각 속성의 특성에 맞는 인코딩을 위해서.

#### 승인 기준

1. WHEN category 필드가 입력되면,
   THE JSON_Encoder SHALL 단일 범주형 데이터로 처리하며
   embedding lookup 방식을 사용한다
2. WHEN style 필드가 입력되면, THE JSON_Encoder SHALL 다중 범주형 데이터로 처리한다
3. WHEN silhouette 필드가 입력되면, THE JSON_Encoder SHALL 단일 범주형 데이터로 처리한다
4. WHEN material 필드가 입력되면, THE JSON_Encoder SHALL 다중 범주형 데이터로 처리한다
5. WHEN detail 필드가 입력되면, THE JSON_Encoder SHALL 다중 범주형 데이터로 처리한다

### 요구사항 3

**사용자 스토리:** 연구자로서, contrastive learning으로 모델을 학습하고 싶다, 이미지와 JSON 메타데이터 간의 의미적 정렬을 위해서.

#### 승인 기준

1. WHEN 학습 데이터가 제공되면, THE 시스템 SHALL positive pair (이미지 임베딩, 해당 JSON)를 생성한다
2. WHEN 학습 데이터가 제공되면, THE 시스템 SHALL negative pair (이미지 임베딩, 다른 JSON들)를 생성한다
3. THE 시스템 SHALL InfoNCE loss 함수를 사용한다 (cosine similarity 기반 loss는 사용하지 않음)

### 요구사항 4

**사용자 스토리:** 연구자로서, 모델 구조를 명확히 이해하고 싶다, 연구 목적에 맞는 구현을 위해서.

#### 승인 기준

1. THE 시스템 SHALL JSON Encoder 모델 구조 다이어그램을 텍스트로 제공한다
2. THE 시스템 SHALL PyTorch Module 클래스 설계를 제공한다
3. THE 시스템 SHALL 입력 필드별 벡터 처리 흐름을 문서화한다
4. THE 시스템 SHALL 학습 시 데이터 흐름을 요약한다

### 요구사항 5

**사용자 스토리:** 연구자로서, 새로운 카테고리별 폴더 구조에서 데이터를 로드하고 싶다, 레트로/로맨틱/리조트 카테고리별로 정리된 데이터를 효율적으로 처리하기 위해서.

#### 승인 기준

1. THE 시스템 SHALL C:/sample/라벨링데이터/{카테고리}/ 경로에서 JSON 파일을 로드한다
2. WHEN load_dataset() 함수가 호출되면, THE 시스템 SHALL 레트로, 로맨틱, 리조트 폴더를 모두 스캔한다
3. WHEN JSON 파일이 발견되면, THE 시스템 SHALL 파일명에서 숫자 ID를 추출하여 매핑한다
4. THE 시스템 SHALL 로드된 데이터 개수와 카테고리별 분포를 출력한다
5. IF 데이터가 로드되지 않았다면, THE 시스템 SHALL "No fashion items loaded. Call load_dataset() first." 오류 대신 구체적인 경로 오류 메시지를 제공한다

### 요구사항 6

**사용자 스토리:** 연구자로서, 모델 복잡도를 제한하고 싶다, 연구 목적에 집중하기 위해서.

#### 승인 기준

1. THE JSON_Encoder SHALL Transformer 구조를 사용하지 않는다
2. THE JSON_Encoder SHALL Attention 메커니즘을 사용하지 않는다
3. THE JSON_Encoder SHALL Graph 구조를 사용하지 않는다
4. THE JSON_Encoder SHALL 과도한 하이퍼파라미터 튜닝을 요구하지 않는다

### 요구사항 7

**사용자 스토리:** 연구자로서, 유사도 검색 시스템을 구현하고 싶다, JSON 쿼리로 유사한 패션 이미지를 찾기 위해서.

#### 승인 기준

1. WHEN JSON 쿼리가 입력되면, THE 시스템 SHALL JSON을 512차원 임베딩으로 변환한다
2. WHEN 이미지 데이터베이스가 제공되면, THE 시스템 SHALL 모든 이미지를 512차원 임베딩으로 변환한다
3. THE 시스템 SHALL JSON 임베딩과 이미지 임베딩 간 코사인 유사도를 계산한다
4. THE 시스템 SHALL Top-K 유사한 이미지를 반환한다 (K는 사용자 지정 가능)
5. THE 시스템 SHALL 검색 결과를 시각화하여 저장한다

### 요구사항 8

**사용자 스토리:** 연구자로서, 모델 성능을 정량적으로 평가하고 싶다, 연구 결과의 객관성을 확보하기 위해서.

#### 승인 기준

1. THE 시스템 SHALL Precision@K 지표를 계산한다 (K=1,5,10)
2. THE 시스템 SHALL Recall@K 지표를 계산한다 (K=1,5,10)
3. THE 시스템 SHALL Mean Reciprocal Rank (MRR) 지표를 계산한다
4. THE 시스템 SHALL 카테고리별 검색 정확도를 분석한다
5. THE 시스템 SHALL 유사도 점수 분포를 시각화한다

### 요구사항 9

**사용자 스토리:** 연구자로서, 체계적인 학습 파이프라인을 구축하고 싶다, 단계별 학습을 통한 안정적인 모델 개발을 위해서.

#### 승인 기준

1. THE 시스템 SHALL 독립 JSON 인코더 학습을 먼저 수행한다 (5 에포크)
2. THE 시스템 SHALL 대조 학습을 후속으로 수행한다 (10 에포크, 향후 50-100 에포크로 확장)
3. THE 시스템 SHALL 배치 사이즈 64-128 범위에서 동작한다
4. THE 시스템 SHALL 학습률 0.0001을 기본값으로 사용한다
5. THE 시스템 SHALL 온도 매개변수 0.07을 사용한다
6. THE 시스템 SHALL 모든 출력 임베딩에 L2 정규화를 적용한다

### 요구사항 10

**사용자 스토리:** 연구자로서, 포괄적인 성능 메트릭을 추적하고 싶다, 모델 성능을 다각도로 평가하기 위해서.

#### 승인 기준

1. THE 시스템 SHALL Top-1 정확도를 계산하고 기록한다
2. THE 시스템 SHALL Top-5 정확도를 계산하고 기록한다
3. THE 시스템 SHALL Mean Reciprocal Rank (MRR)를 계산한다
4. THE 시스템 SHALL Positive Similarity 평균을 추적한다
5. THE 시스템 SHALL Negative Similarity 평균을 추적한다
6. THE 시스템 SHALL 임베딩 정규화 상태를 확인한다 (L2 norm = 1)

### 요구사항 11

**사용자 스토리:** 연구자로서, 하이퍼파라미터 튜닝 계획을 수립하고 싶다, 체계적인 성능 개선을 위해서.

#### 승인 기준

1. THE 시스템 SHALL 학습 에포크를 50-100으로 확장 가능해야 한다
2. THE 시스템 SHALL 배치 사이즈를 64-128 범위에서 조정 가능해야 한다
3. THE 시스템 SHALL 학습률 튜닝을 지원한다
4. THE 시스템 SHALL 온도 매개변수 튜닝을 지원한다
5. THE 시스템 SHALL 임베딩 차원 실험을 지원한다
6. THE 시스템 SHALL 자동 튜닝 도구 연동을 고려한다 (Optuna, Ray Tune, W&B Sweep)

### 요구사항 12

**사용자 스토리:** 연구자로서, 학습 결과물을 체계적으로 관리하고 싶다, 재현 가능한 연구를 위해서.

#### 승인 기준

1. THE 시스템 SHALL 모델 체크포인트를 `checkpoints/best_model.pt`에 저장한다
2. THE 시스템 SHALL 학습 결과를 `results/training_results.json`에 저장한다
3. THE 시스템 SHALL 시각화 이미지를 `results/*.png`에 저장한다
4. THE 시스템 SHALL 유사도 검색 결과를 `results/similarity_search/`에 저장한다
5. THE 시스템 SHALL 모든 결과물에 타임스탬프를 포함한다

### 요구사항 13

**사용자 스토리:** 연구자로서, 자동 하이퍼파라미터 튜닝 시스템을 구축하고 싶다, 체계적이고 효율적인 성능 최적화를 위해서.

#### 승인 기준

1. THE 시스템 SHALL Optuna 기반 베이지안 최적화를 지원한다
2. THE 시스템 SHALL Ray Tune 기반 분산 튜닝을 지원한다
3. THE 시스템 SHALL W&B Sweep 기반 실험 추적을 지원한다
4. THE 시스템 SHALL 다음 하이퍼파라미터 범위에서 탐색한다:
   - 에포크: 50-100
   - 배치 사이즈: 64, 96, 128
   - 학습률: 0.0001-0.001
   - 온도(T): 0.05-0.1
   - 임베딩 차원: 256, 512, 768
5. THE 시스템 SHALL 조기 종료(Early Stopping) 기능을 제공한다

### 요구사항 14

**사용자 스토리:** 연구자로서, 데이터 증강 시스템을 구현하고 싶다, 모델의 일반화 성능 향상을 위해서.

#### 승인 기준

1. THE 시스템 SHALL 이미지 데이터 증강을 지원한다 (rotation, flip, color jitter, brightness, contrast)
2. THE 시스템 SHALL JSON 데이터 증강을 지원한다 (field dropout, synonym replacement)
3. THE 시스템 SHALL 증강 확률을 조정 가능해야 한다 (0.0-1.0)
4. THE 시스템 SHALL 증강 적용 전후 성능 비교를 제공한다
5. THE 시스템 SHALL 카테고리별 증강 효과를 분석한다

### 요구사항 15

**사용자 스토리:** 연구자로서, 고급 모델 구조를 실험하고 싶다, 더 나은 표현 학습을 위해서.

#### 승인 기준

1. THE 시스템 SHALL Multi-head Attention 기반 JSON 인코더를 지원한다
2. THE 시스템 SHALL 더 깊은 네트워크 구조를 실험할 수 있다 (3-5 레이어)
3. THE 시스템 SHALL 잔차 연결(Residual Connection)을 지원한다
4. THE 시스템 SHALL 배치 정규화(Batch Normalization) 옵션을 제공한다
5. THE 시스템 SHALL 기존 단순 구조와 성능 비교를 제공한다

### 요구사항 16

**사용자 스토리:** 연구자로서, 현재 JSON Encoder 학습 상태와 유사도 검색 결과를 대시보드에서 확인하고 싶다, 초기 성능이 낮더라도 구조를 먼저 확인하고 모니터링 가능해야 한다.

#### 승인 기준

##### 대시보드 구조 제공
1. THE 시스템 SHALL 상단 KPI 카드 영역을 제공한다
   - 총 학습 데이터 수, 카테고리별 아이템 수
   - 현재 학습 에포크 및 진행률
   - Top-1 / Top-5 정확도, MRR, Positive/Negative Similarity
   - 임베딩 정규화 상태(L2 norm)

2. THE 시스템 SHALL 학습 손실 및 메트릭 시각화 영역을 제공한다
   - Train / Validation Loss 곡선
   - 임베딩 정규화 통계
   - 학습률(LR) 변화

3. THE 시스템 SHALL 유사도 검색 시각화 영역을 제공한다
   - 카테고리별 Top-K 유사 이미지
   - JSON 쿼리 ↔ 이미지 코사인 유사도 점수 표시

4. THE 시스템 SHALL 하이퍼파라미터 / 튜닝 관리 영역을 제공한다
   - 현재 batch size, epochs, learning rate, temperature 등 표시
   - 자동 튜닝 결과 요약 (실험적)

5. THE 시스템 SHALL 데이터 증강 샘플 확인 영역을 제공한다
   - 이미지 증강 예시: 회전, flip, color jitter
   - JSON 증강 예시: Field Dropout, Synonym Replacement

6. THE 시스템 SHALL 실용화 상태 / 배포 모니터링 영역을 제공한다 (실험적)
   - GPU 사용량, FAISS 인덱스 상태, 평균 응답 시간

##### 데이터 제공 형식
7. THE 시스템 SHALL JSON Encoder 학습 및 유사도 검색 관련 데이터를 REST API 또는 JSON 파일 형태로 제공한다

8. THE 데이터 SHALL 각 영역별로 필요한 값과 구조를 포함해야 한다
   - 예: `{ kpi: {...}, loss_curve: [...], top_k_images: [...], hyperparams: {...}, augmented_samples: [...] }`

##### 초기 성능 상태 반영
9. 현재 Top-5 정확도, MRR 등 지표가 낮더라도, THE 시스템 SHALL 구조 및 시각화 가능 상태를 유지한다

10. 추후 학습 성능 개선 시, 대시보드에 즉시 반영 가능해야 한다

##### 컴포넌트 연동 고려
11. THE 시스템 SHALL Nest.js 기반 프론트와 연동 가능하도록 각 영역별 props/데이터 키를 명시한다

12. THE 시스템 SHALL 이미지/차트/JSON 데이터 모두 대시보드에서 바로 렌더링 가능해야 한다

##### 학습 진행 상태 시각화
13. THE 시스템 SHALL 학습이 진행 중이거나 중단된 상태에서도 현재까지의 학습 진행 상황을 시각적으로 제공해야 한다:
    - 현재 학습 단계 (독립 JSON 인코더 / 대조 학습)
    - 현재 에포크 / 전체 에포크
    - 마지막 체크포인트 시점
    - Train / Validation Loss 값
    - 최신 Top-1 / Top-5 정확도
    - 최신 MRR
    - Positive / Negative Similarity 평균
    - 임베딩 L2 정규화 상태

14. THE 시스템 SHALL 학습이 중단된 경우에도, 마지막 저장된 체크포인트 기준의 지표를 대시보드에 표시해야 한다

### 요구사항 17

**사용자 스토리:** 연구자로서, 테스트와 데모를 빠르게 실행하고 싶다, 개발 과정에서 빠른 피드백을 받기 위해서.

#### 승인 기준

##### 테스트 성능 최적화
1. THE 시스템 SHALL 유사도 검색 데모에서 샘플 이미지 수를 조정 가능해야 한다 (기본값: 20개, 최대 100개)
2. THE 시스템 SHALL 단위 테스트에서 작은 배치 크기를 사용해야 한다 (테스트용 배치 크기: 2-4개)
3. THE 시스템 SHALL 테스트 모드에서 에포크 수를 줄여야 한다 (테스트용: 1-2 에포크)
4. THE 시스템 SHALL CPU 모드에서도 안정적으로 동작해야 한다

##### 빠른 실행 옵션
5. THE 시스템 SHALL 데모 스크립트에 `--fast` 또는 `--quick` 옵션을 제공해야 한다
6. WHEN `--fast` 옵션이 사용되면, THE 시스템 SHALL 샘플 수를 20개로 제한한다
7. WHEN `--quick` 옵션이 사용되면, THE 시스템 SHALL 시각화를 생략하고 결과만 출력한다
8. THE 시스템 SHALL 테스트 실행 시간을 30초 이내로 유지해야 한다

##### 개발 편의성
9. THE 시스템 SHALL 테스트 결과를 간결하게 요약해서 출력해야 한다
10. THE 시스템 SHALL 실패한 테스트에 대해 명확한 오류 메시지를 제공해야 한다
11. THE 시스템 SHALL 메모리 사용량을 최소화해야 한다 (GPU 메모리 < 2GB)
12. THE 시스템 SHALL 불필요한 로그 출력을 줄여야 한다

### 요구사항 18

**사용자 스토리:** 연구자 및 개발자로서, 학습 진행 상황을 간단하게 모니터링하고 싶다. tqdm 진행 바로 실시간 진행률을 확인하고, matplotlib으로 기본적인 학습 차트를 생성하여 학습 결과를 시각적으로 파악할 수 있어야 한다.

#### 승인 기준

##### 18.1 tqdm 기반 진행 바
THE 시스템 SHALL tqdm을 사용하여 학습 진행 상황을 표시한다:
- 현재 에포크 / 전체 에포크 진행률
- 경과 시간 및 예상 완료 시간
- 주요 메트릭 (검증 손실, Top-5 정확도, MRR) 실시간 표시

##### 18.2 matplotlib 기본 차트
THE 시스템 SHALL matplotlib을 사용하여 학습 완료 후 기본 차트를 생성한다:
- 2x2 서브플롯 구성
- 학습/검증 손실 곡선
- Top-K 정확도 변화
- Mean Reciprocal Rank (MRR) 변화
- Positive/Negative Similarity 변화

##### 18.3 간단한 결과 저장
THE 시스템 SHALL 학습 결과를 간단한 형태로 저장한다:
- training_summary.json: 메트릭 히스토리 및 학습 상태
- training_charts.png: matplotlib 차트 이미지
- 콘솔 출력: 학습 시작/완료 메시지

##### 18.4 최소 의존성
THE 시스템 SHALL 최소한의 라이브러리만 사용한다:
- tqdm: 진행 바 표시
- matplotlib: 기본 차트 생성
- 복잡한 대시보드나 실시간 웹 인터페이스 불필요

##### 18.5 개발 편의성
THE 시스템 SHALL 개발 과정에서 빠른 피드백을 제공한다:
- 콘솔에서 즉시 확인 가능한 진행률
- 학습 완료 후 자동 차트 생성
- 간단하고 직관적인 출력 형식

## 학습 파이프라인 사양

### 1단계: 독립 JSON 인코더 학습
- **에포크**: 5
- **배치 사이즈**: 64
- **임베딩 차원**: 512
- **출력 정규화**: L2 norm 유지
- **목적**: JSON 인코더 단독 학습으로 기본 표현 학습

### 2단계: 대조 학습 (Contrastive Learning)
- **에포크**: 10 (향후 50-100으로 확장 예정)
- **배치 사이즈**: 64-128 범위 권장
- **학습률**: 0.0001
- **온도(T)**: 0.07
- **목적**: 이미지-JSON 임베딩 공간 정렬

### 유사도 검색 사양
- **입력**: JSON 쿼리 (카테고리별)
- **처리**: JSON → 512차원 임베딩 변환
- **비교**: 이미지 임베딩과 코사인 유사도 계산
- **출력**: 카테고리별 Top-5 이미지 시각화 및 결과 저장
- **검증**: 초기 학습 단계에서도 의미 있는 유사도 결과 확인

## 성능 메트릭 정의

### 정량적 지표
- **Top-1 정확도**: 가장 유사한 이미지가 정답인 비율
- **Top-5 정확도**: 상위 5개 중 정답이 포함된 비율
- **Mean Reciprocal Rank (MRR)**: 정답의 평균 역순위
- **Positive Similarity**: 매칭 쌍의 평균 유사도
- **Negative Similarity**: 비매칭 쌍의 평균 유사도

### 정성적 지표
- **임베딩 정규화**: L2 norm = 1 확인
- **카테고리별 클러스터링**: 시각적 분석
- **검색 품질**: 사용자 관점 평가

## 자동 하이퍼파라미터 튜닝 계획

### 지원 도구 및 프레임워크

#### Optuna (베이지안 최적화)
- **장점**: 효율적인 하이퍼파라미터 탐색, 조기 종료 지원
- **적용 범위**: 소규모-중규모 실험 (단일 GPU)
- **최적화 알고리즘**: TPE (Tree-structured Parzen Estimator)

#### Ray Tune (분산 튜닝)
- **장점**: 대규모 분산 실험, 다양한 스케줄러 지원
- **적용 범위**: 대규모 실험 (다중 GPU/노드)
- **스케줄러**: ASHA, PopulationBasedTraining

#### W&B Sweep (실험 추적)
- **장점**: 실험 시각화, 협업 지원, 결과 분석
- **적용 범위**: 모든 규모의 실험
- **탐색 방법**: Grid, Random, Bayesian

### 튜닝 대상 하이퍼파라미터

#### 우선순위 1: 학습 설정
- **에포크**: 50, 75, 100
- **배치 사이즈**: 64, 96, 128
- **학습률**: 0.0001, 0.0003, 0.0005, 0.001
- **온도(T)**: 0.05, 0.07, 0.1

#### 우선순위 2: 모델 구조
- **임베딩 차원**: 256, 512, 768
- **은닉층 차원**: 256, 512, 1024
- **드롭아웃 비율**: 0.1, 0.2, 0.3

#### 우선순위 3: 정규화 및 최적화
- **가중치 감쇠**: 1e-5, 1e-4, 1e-3
- **스케줄러**: CosineAnnealingLR, StepLR, ExponentialLR
- **그래디언트 클리핑**: 0.5, 1.0, 2.0

### 튜닝 전략

#### 단계별 접근법
1. **1단계**: 기본 하이퍼파라미터 (에포크, 배치, 학습률) - 20회 실험
2. **2단계**: 모델 구조 (임베딩, 은닉층) - 15회 실험  
3. **3단계**: 세부 튜닝 (정규화, 스케줄러) - 10회 실험

#### 평가 지표
- **주 지표**: Top-5 정확도
- **보조 지표**: MRR, 학습 안정성, 수렴 속도
- **조기 종료**: 검증 손실 기준 (patience=10)

### 구현 고려사항

#### 현재 상태
- **현재 코드**: 자동 튜닝 미포함
- **필요 작업**: 별도 튜닝 스크립트 개발
- **예상 시간**: 튜닝 스크립트 개발 1-2일, 실험 실행 1-2주

#### 리소스 요구사항
- **GPU 메모리**: 배치 128 기준 8GB+ 권장
- **실험 시간**: 100 에포크 기준 2-4시간/실험
- **저장 공간**: 체크포인트 및 로그 파일 10GB+ 예상

## 데이터 증강 전략

### 이미지 데이터 증강

#### 기본 증강 기법
- **회전**: ±15도 범위
- **수평 뒤집기**: 50% 확률
- **색상 조정**: brightness(±0.2), contrast(±0.2), saturation(±0.2)
- **크롭 및 리사이즈**: RandomResizedCrop (0.8-1.0 비율)

#### 고급 증강 기법
- **MixUp**: 이미지 쌍 선형 결합
- **CutMix**: 이미지 영역 교체
- **AutoAugment**: 자동 증강 정책 학습

### JSON 데이터 증강

#### 필드별 증강 전략
- **Field Dropout**: 20% 확률로 필드 마스킹
- **Synonym Replacement**: 스타일/소재 유의어 교체
- **Attribute Mixing**: 동일 카테고리 내 속성 혼합

#### 카테고리별 증강
- **레트로**: 빈티지, 클래식 스타일 강화
- **로맨틱**: 페미닌, 우아함 속성 강화  
- **리조트**: 캐주얼, 편안함 속성 강화

## 고급 모델 구조 실험 계획

### Multi-head Attention 기반 JSON 인코더

#### 구조 설계
```
JSON Fields → Field Embeddings → Multi-head Attention → Layer Norm → MLP → Output
```

#### 설정 옵션
- **헤드 수**: 4, 8, 16
- **어텐션 차원**: 128, 256, 512
- **레이어 수**: 2, 4, 6

### 깊은 네트워크 구조

#### 잔차 연결 (Residual Connection)
- **ResNet 스타일**: Skip connection 적용
- **레이어 수**: 3, 5, 7층
- **활성화 함수**: ReLU, GELU, Swish

#### 정규화 기법
- **Batch Normalization**: 각 레이어 후 적용
- **Layer Normalization**: Transformer 스타일
- **Dropout**: 0.1, 0.2, 0.3 비율

### 성능 비교 프레임워크

#### 기준 모델
- **Baseline**: 현재 단순 MLP 구조
- **비교 지표**: Top-K 정확도, MRR, 학습 시간, 메모리 사용량

#### 실험 설계
- **A/B 테스트**: 동일 데이터셋, 동일 하이퍼파라미터
- **통계적 유의성**: 5회 반복 실험, t-test 적용
- **효율성 분석**: FLOPs, 파라미터 수, 추론 시간

## 실용화 로드맵

### Phase 1: 웹 기반 검색 인터페이스

#### 기술 스택
- **백엔드**: FastAPI, PyTorch
- **프론트엔드**: Nest.js, TypeScript
- **데이터베이스**: PostgreSQL (메타데이터), Redis (캐싱)

#### 핵심 기능
- **JSON 쿼리 입력**: 웹 폼 기반 인터페이스
- **실시간 검색**: 1초 이내 응답
- **결과 시각화**: 그리드 뷰, 유사도 점수 표시

### Phase 2: 추론 최적화

#### 모델 최적화
- **양자화**: INT8, FP16 정밀도 감소
- **모델 압축**: Knowledge Distillation
- **배치 처리**: 동적 배치 크기 조정

#### 시스템 최적화
- **임베딩 캐싱**: 사전 계산된 이미지 임베딩
- **인덱싱**: FAISS 기반 근사 최근접 이웃 탐색
- **로드 밸런싱**: 다중 GPU 추론 서버

### Phase 3: 대용량 데이터베이스 지원

#### 확장성 설계
- **분산 저장**: 이미지 및 임베딩 분산 저장
- **스트리밍 처리**: Apache Kafka 기반 실시간 데이터 처리
- **자동 스케일링**: Kubernetes 기반 오토스케일링

#### 성능 목표
- **데이터베이스 크기**: 100,000+ 이미지 지원
- **동시 사용자**: 1,000+ 동시 검색 요청
- **응답 시간**: 평균 500ms 이하

### Phase 4: 사용자 피드백 시스템

#### 피드백 수집
- **명시적 피드백**: 좋아요/싫어요, 별점
- **암시적 피드백**: 클릭률, 체류 시간
- **A/B 테스트**: 다양한 랭킹 알고리즘 비교

#### 개선 사이클
- **피드백 분석**: 주간/월간 성능 리포트
- **모델 재학습**: 피드백 데이터 기반 지속적 학습
- **개인화**: 사용자별 선호도 학습

## 구현 우선순위 및 일정

### 단기 계획 (1-2개월)
1. **자동 튜닝 스크립트 개발**: Optuna 기반 기본 튜닝
2. **데이터 증강 구현**: 이미지 증강 우선 적용
3. **성능 개선**: 50-100 에포크 학습 실행

### 중기 계획 (3-6개월)  
1. **고급 모델 구조**: Multi-head Attention 실험
2. **웹 인터페이스**: 기본 검색 시스템 구축
3. **추론 최적화**: 모델 압축 및 캐싱 시스템

### 장기 계획 (6-12개월)
1. **대용량 시스템**: 분산 처리 및 확장성 구현
2. **사용자 피드백**: 개인화 및 지속적 학습
3. **상용화**: 실제 서비스 배포 및 운영

## 리소스 및 제약사항

### 하드웨어 요구사항
- **개발 환경**: GPU 8GB+ (RTX 3070 이상)
- **실험 환경**: GPU 16GB+ (RTX 4080 이상) 또는 클라우드
- **서비스 환경**: 다중 GPU 서버 또는 클라우드 인프라

### 소프트웨어 의존성
- **ML 프레임워크**: PyTorch, Transformers, CLIP
- **튜닝 도구**: Optuna, Ray Tune, W&B
- **웹 프레임워크**: FastAPI, Nest.js
- **데이터베이스**: PostgreSQL, Redis, FAISS

### 예산 고려사항
- **클라우드 비용**: GPU 인스턴스 월 $500-2000
- **스토리지 비용**: 대용량 이미지 저장 월 $100-500
- **도구 라이선스**: W&B Pro, 기타 상용 도구

## 결과물 관리 체계

### 모델 아티팩트
- **체크포인트**: `checkpoints/best_model.pt` (최고 성능 모델)
- **중간 체크포인트**: `checkpoints/checkpoint_epoch_*.pt`
- **설정 파일**: 모델 하이퍼파라미터 및 학습 설정

### 학습 결과
- **메트릭**: `results/training_results.json` (모든 성능 지표)
- **로그**: TensorBoard 로그 파일
- **시각화**: `results/*.png` (손실 곡선, 임베딩 분포 등)

### 검색 결과
- **데모 결과**: `results/similarity_search/` (쿼리별 Top-5 이미지)
- **분석 보고서**: 검색 품질 분석 및 개선 방향
- **시각화**: 유사도 히트맵, 임베딩 공간 시각화

## 현재 구현 상태 (2026-02-04 기준)

### ✅ 완료된 기능
- **전체 파이프라인**: JSON → 임베딩 → 이미지 임베딩 → 코사인 유사도 계산
- **데이터 로딩**: K-Fashion 데이터셋 2,172개 아이템 로드 (레트로: 196, 로맨틱: 994, 리조트: 998)
- **모델 학습**: 15 에포크 초기 학습 완료 (독립 학습 5 + 대조 학습 10)
- **유사도 검색**: Top-5 유사 이미지 검색 및 시각화 데모 구현
- **시스템 안정성**: 오류 없는 전체 파이프라인 실행
- **재사용성**: test_similarity_search.py 스크립트 제공

### 📊 현재 성능 지표
- **Top-5 정확도**: 1.04%
- **유사도 범위**: 0.0146~0.0340 (의미있는 값 생성)
- **평균 역순위**: 0.0543
- **임베딩 정규화**: L2 정규화 완료

### ⚠️ 현재 한계사항
- **학습 부족**: 15 에포크로 성능 제한
- **하이퍼파라미터**: 기본값 사용, 튜닝 미적용
- **데이터 증강**: 미적용 상태
- **모델 구조**: 단순한 MLP 기반 구조
- **평가 지표**: Top-K 유사도만 확인, 정량적 평가 부족

## 향후 개발 계획

### Phase 1: 성능 개선 (우선순위: 높음) - 1-2개월
1. **학습 확대**: 50-100 에포크로 확장
2. **자동 하이퍼파라미터 튜닝**: Optuna/Ray Tune/W&B Sweep 구현
3. **정량적 평가**: Precision@K, Recall@K, MRR 지표 구현
4. **조기 종료**: 효율적인 학습을 위한 Early Stopping

### Phase 2: 데이터 증강 (우선순위: 중간) - 2-3개월
1. **이미지 증강**: rotation, flip, color jitter, MixUp, CutMix 적용
2. **JSON 증강**: field dropout, synonym replacement, attribute mixing
3. **어휘 확장**: 더 풍부한 vocabulary 구축
4. **카테고리별 증강**: 레트로/로맨틱/리조트 특성 강화

### Phase 3: 모델 구조 개선 (우선순위: 중간) - 3-4개월
1. **Multi-head Attention**: JSON 인코더 고도화
2. **깊은 네트워크**: 3-5층 구조, 잔차 연결
3. **정규화 기법**: Batch/Layer Normalization 실험
4. **특성 강화**: 스타일, 컬러, 아이템별 특성 표현력 향상

### Phase 4: 실용화 (우선순위: 낮음) - 6-12개월
1. **웹 기반 검색**: Nest.js + FastAPI 기반 인터페이스
2. **추론 최적화**: 모델 양자화, 배치 처리, FAISS 인덱싱
3. **대용량 지원**: 100,000+ 이미지 데이터베이스
4. **사용자 피드백**: 개인화 및 지속적 학습 시스템

## 전역 제약 사항

1. JSON_Encoder의 출력 차원은 모든 경우에 512로 고정된다
2. 출력 차원 변경을 위한 실험 또는 대안 설계는 본 연구 범위에 포함되지 않는다
3. FashionCLIP 이미지 인코더는 frozen 상태를 유지한다
4. 모든 개선사항은 기존 파이프라인과의 호환성을 유지해야 한다