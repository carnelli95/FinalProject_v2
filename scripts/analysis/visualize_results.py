#!/usr/bin/env python3
"""
Fashion JSON Encoder í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•™ìŠµ ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['Malgun Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def load_training_results(results_path: str = "results/training_results.json"):
    """í•™ìŠµ ê²°ê³¼ ë¡œë“œ"""
    with open(results_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def plot_training_losses(results):
    """í•™ìŠµ ì†ì‹¤ ì‹œê°í™”"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # ë…ë¦½ í•™ìŠµ ì†ì‹¤
    standalone = results['standalone']
    epochs_standalone = range(1, len(standalone['train_losses']) + 1)
    
    axes[0].plot(epochs_standalone, standalone['train_losses'], 'b-o', label='Train Loss', linewidth=2, markersize=6)
    axes[0].plot(epochs_standalone, standalone['val_losses'], 'r-s', label='Validation Loss', linewidth=2, markersize=6)
    axes[0].set_title('ë…ë¦½ JSON ì¸ì½”ë” í•™ìŠµ', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    axes[0].set_ylim(0.99, 1.01)
    
    # ëŒ€ì¡° í•™ìŠµ ì†ì‹¤
    contrastive = results['contrastive']
    epochs_contrastive = range(1, len(contrastive['train_losses']) + 1)
    
    axes[1].plot(epochs_contrastive, contrastive['train_losses'], 'b-o', label='Train Loss', linewidth=2, markersize=6)
    axes[1].plot(epochs_contrastive, contrastive['val_losses'], 'r-s', label='Validation Loss', linewidth=2, markersize=6)
    axes[1].set_title('ëŒ€ì¡° í•™ìŠµ (Contrastive Learning)', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Loss')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/training_losses.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_output_statistics(results):
    """ì¶œë ¥ í†µê³„ ì‹œê°í™”"""
    standalone = results['standalone']
    output_stats = standalone['output_stats']
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    epochs = range(1, len(output_stats) + 1)
    
    # Mean ë³€í™”
    means = [stat['mean'] for stat in output_stats]
    axes[0, 0].plot(epochs, means, 'g-o', linewidth=2, markersize=6)
    axes[0, 0].set_title('ì„ë² ë”© í‰ê· ê°’ ë³€í™”', fontweight='bold')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Mean')
    axes[0, 0].grid(True, alpha=0.3)
    
    # Std ë³€í™”
    stds = [stat['std'] for stat in output_stats]
    axes[0, 1].plot(epochs, stds, 'm-s', linewidth=2, markersize=6)
    axes[0, 1].set_title('ì„ë² ë”© í‘œì¤€í¸ì°¨ ë³€í™”', fontweight='bold')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Standard Deviation')
    axes[0, 1].grid(True, alpha=0.3)
    
    # Norm ë³€í™”
    norms = [stat['norm'] for stat in output_stats]
    axes[1, 0].plot(epochs, norms, 'c-^', linewidth=2, markersize=6)
    axes[1, 0].set_title('L2 ì •ê·œí™” ìƒíƒœ', fontweight='bold')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('L2 Norm')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_ylim(0.999, 1.001)
    
    # Learning Rate ë³€í™” (ëŒ€ì¡° í•™ìŠµ)
    contrastive = results['contrastive']
    lr_epochs = range(1, len(contrastive['learning_rates']) + 1)
    axes[1, 1].plot(lr_epochs, contrastive['learning_rates'], 'orange', linewidth=2)
    axes[1, 1].set_title('í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§', fontweight='bold')
    axes[1, 1].set_xlabel('Epoch (Contrastive)')
    axes[1, 1].set_ylabel('Learning Rate')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
    
    plt.tight_layout()
    plt.savefig('results/output_statistics.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_performance_metrics(results):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œê°í™”"""
    contrastive = results['contrastive']
    final_metrics = contrastive['final_metrics']
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # ì •í™•ë„ ë©”íŠ¸ë¦­
    accuracies = ['Top-1', 'Top-5']
    acc_values = [final_metrics['top1_accuracy'] * 100, final_metrics['top5_accuracy'] * 100]
    
    bars1 = axes[0, 0].bar(accuracies, acc_values, color=['#FF6B6B', '#4ECDC4'], alpha=0.8)
    axes[0, 0].set_title('ê²€ìƒ‰ ì •í™•ë„', fontweight='bold')
    axes[0, 0].set_ylabel('ì •í™•ë„ (%)')
    axes[0, 0].grid(True, alpha=0.3, axis='y')
    
    # ë°” ìœ„ì— ê°’ í‘œì‹œ
    for bar, value in zip(bars1, acc_values):
        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                       f'{value:.2f}%', ha='center', va='bottom', fontweight='bold')
    
    # ìœ ì‚¬ë„ ë¶„í¬
    pos_sim = final_metrics['positive_similarity_mean']
    neg_sim = final_metrics['negative_similarity_mean']
    
    similarities = ['Positive\nSimilarity', 'Negative\nSimilarity']
    sim_values = [pos_sim, neg_sim]
    
    bars2 = axes[0, 1].bar(similarities, sim_values, color=['#95E1D3', '#F38BA8'], alpha=0.8)
    axes[0, 1].set_title('ìœ ì‚¬ë„ ë¹„êµ', fontweight='bold')
    axes[0, 1].set_ylabel('Cosine Similarity')
    axes[0, 1].grid(True, alpha=0.3, axis='y')
    
    # ë°” ìœ„ì— ê°’ í‘œì‹œ
    for bar, value in zip(bars2, sim_values):
        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                       f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
    
    # MRR ì‹œê°í™”
    mrr = final_metrics['mean_reciprocal_rank']
    axes[1, 0].bar(['Mean Reciprocal\nRank'], [mrr], color='#A8E6CF', alpha=0.8)
    axes[1, 0].set_title('í‰ê·  ì—­ìˆœìœ„ (MRR)', fontweight='bold')
    axes[1, 0].set_ylabel('MRR')
    axes[1, 0].grid(True, alpha=0.3, axis='y')
    axes[1, 0].text(0, mrr + 0.002, f'{mrr:.4f}', ha='center', va='bottom', fontweight='bold')
    
    # ì„ë² ë”© ì •ê·œí™” ìƒíƒœ
    norms = ['Image\nEmbedding', 'JSON\nEmbedding']
    norm_values = [final_metrics['image_embedding_norm'], final_metrics['json_embedding_norm']]
    
    bars4 = axes[1, 1].bar(norms, norm_values, color=['#FFB6C1', '#87CEEB'], alpha=0.8)
    axes[1, 1].set_title('ì„ë² ë”© ì •ê·œí™” ìƒíƒœ', fontweight='bold')
    axes[1, 1].set_ylabel('L2 Norm')
    axes[1, 1].grid(True, alpha=0.3, axis='y')
    axes[1, 1].set_ylim(0.99, 1.01)
    
    # ë°” ìœ„ì— ê°’ í‘œì‹œ
    for bar, value in zip(bars4, norm_values):
        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                       f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('results/performance_metrics.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_dataset_distribution():
    """ë°ì´í„°ì…‹ ë¶„í¬ ì‹œê°í™”"""
    categories = ['ë ˆíŠ¸ë¡œ', 'ë¡œë§¨í‹±', 'ë¦¬ì¡°íŠ¸']
    counts = [196, 994, 998]
    total = sum(counts)
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # íŒŒì´ ì°¨íŠ¸
    colors = ['#FF9999', '#66B2FF', '#99FF99']
    wedges, texts, autotexts = axes[0].pie(counts, labels=categories, colors=colors, autopct='%1.1f%%',
                                          startangle=90, textprops={'fontsize': 12})
    axes[0].set_title('ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ë¶„í¬', fontsize=14, fontweight='bold')
    
    # ë§‰ëŒ€ ì°¨íŠ¸
    bars = axes[1].bar(categories, counts, color=colors, alpha=0.8)
    axes[1].set_title('ì¹´í…Œê³ ë¦¬ë³„ ì•„ì´í…œ ìˆ˜', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('ì•„ì´í…œ ìˆ˜')
    axes[1].grid(True, alpha=0.3, axis='y')
    
    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bar, count in zip(bars, counts):
        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,
                    f'{count}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('results/dataset_distribution.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"ì´ ë°ì´í„°ì…‹ í¬ê¸°: {total:,}ê°œ ì•„ì´í…œ")
    print(f"í•™ìŠµ/ê²€ì¦ ë¶„í• : {int(total * 0.8):,}ê°œ / {int(total * 0.2):,}ê°œ")

def create_summary_report(results):
    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    standalone = results['standalone']
    contrastive = results['contrastive']
    
    print("=" * 60)
    print("ğŸ¯ Fashion JSON Encoder í•™ìŠµ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    print("\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
    print(f"  â€¢ ì´ ì•„ì´í…œ ìˆ˜: 2,172ê°œ")
    print(f"  â€¢ ì¹´í…Œê³ ë¦¬: ë ˆíŠ¸ë¡œ(196), ë¡œë§¨í‹±(994), ë¦¬ì¡°íŠ¸(998)")
    print(f"  â€¢ í•™ìŠµ/ê²€ì¦ ë¶„í• : 1,737ê°œ / 435ê°œ")
    
    print("\nğŸ‹ï¸ ë…ë¦½ í•™ìŠµ (5 ì—í¬í¬):")
    print(f"  â€¢ ìµœì¢… Train Loss: {standalone['train_losses'][-1]:.4f}")
    print(f"  â€¢ ìµœì¢… Val Loss: {standalone['val_losses'][-1]:.4f}")
    print(f"  â€¢ ì„ë² ë”© ì •ê·œí™”: âœ… (norm={standalone['final_analysis']['norm_mean']:.6f})")
    
    print("\nğŸ”„ ëŒ€ì¡° í•™ìŠµ (10 ì—í¬í¬):")
    print(f"  â€¢ ìµœê³  Val Loss: {contrastive['best_val_loss']:.4f}")
    print(f"  â€¢ ìµœì¢… Train Loss: {contrastive['train_losses'][-1]:.4f}")
    print(f"  â€¢ ìµœì¢… Val Loss: {contrastive['val_losses'][-1]:.4f}")
    
    print("\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
    final_metrics = contrastive['final_metrics']
    print(f"  â€¢ Top-1 ì •í™•ë„: {final_metrics['top1_accuracy']*100:.2f}%")
    print(f"  â€¢ Top-5 ì •í™•ë„: {final_metrics['top5_accuracy']*100:.2f}%")
    print(f"  â€¢ Mean Reciprocal Rank: {final_metrics['mean_reciprocal_rank']:.4f}")
    print(f"  â€¢ í‰ê·  Positive Similarity: {final_metrics['avg_positive_similarity']:.4f}")
    print(f"  â€¢ í‰ê·  Negative Similarity: {final_metrics['negative_similarity_mean']:.4f}")
    
    print("\nâœ… ëª¨ë¸ ìƒíƒœ:")
    print(f"  â€¢ ì´ë¯¸ì§€ ì„ë² ë”© ì •ê·œí™”: {final_metrics['image_embedding_norm']:.3f}")
    print(f"  â€¢ JSON ì„ë² ë”© ì •ê·œí™”: {final_metrics['json_embedding_norm']:.3f}")
    print(f"  â€¢ ì„ë² ë”© ì°¨ì›: {final_metrics['embedding_dim']}ì°¨ì›")
    
    print("\nğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
    print(f"  â€¢ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸: checkpoints/best_model.pt")
    print(f"  â€¢ í•™ìŠµ ê²°ê³¼: results/training_results.json")
    print(f"  â€¢ ì‹œê°í™” ê²°ê³¼: results/*.png")
    
    print("=" * 60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    Path("results").mkdir(exist_ok=True)
    
    # í•™ìŠµ ê²°ê³¼ ë¡œë“œ
    try:
        results = load_training_results()
    except FileNotFoundError:
        print("âŒ í•™ìŠµ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: results/training_results.json")
        return
    
    print("ğŸ¨ Fashion JSON Encoder í•™ìŠµ ê²°ê³¼ ì‹œê°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥
    create_summary_report(results)
    
    # ì‹œê°í™” ìƒì„±
    print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    
    try:
        # 1. í•™ìŠµ ì†ì‹¤ ê·¸ë˜í”„
        print("  â€¢ í•™ìŠµ ì†ì‹¤ ê·¸ë˜í”„ ìƒì„±...")
        plot_training_losses(results)
        
        # 2. ì¶œë ¥ í†µê³„ ê·¸ë˜í”„
        print("  â€¢ ì¶œë ¥ í†µê³„ ê·¸ë˜í”„ ìƒì„±...")
        plot_output_statistics(results)
        
        # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê·¸ë˜í”„
        print("  â€¢ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê·¸ë˜í”„ ìƒì„±...")
        plot_performance_metrics(results)
        
        # 4. ë°ì´í„°ì…‹ ë¶„í¬ ê·¸ë˜í”„
        print("  â€¢ ë°ì´í„°ì…‹ ë¶„í¬ ê·¸ë˜í”„ ìƒì„±...")
        plot_dataset_distribution()
        
        print("\nâœ… ëª¨ë“  ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì´ results/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("matplotlib ì„¤ì¹˜ í™•ì¸: pip install matplotlib seaborn")

if __name__ == "__main__":
    main()