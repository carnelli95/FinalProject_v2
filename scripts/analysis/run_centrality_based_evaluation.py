#!/usr/bin/env python3
"""
ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€ ì‹¤í–‰

ì„ë² ë”© ì¤‘ì‹¬ì„± ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œë“œí•˜ì—¬ ì •í™•í•œ Anchor ì¸ë±ìŠ¤ë¡œ í‰ê°€ ìˆ˜í–‰
"""

import sys
import json
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from scripts.analysis.embedding_centrality_proxy import run_embedding_centrality_analysis
from scripts.analysis.anchor_based_evaluation import AnchorBasedEvaluator
from main import FashionEncoderSystem
from utils.config import TrainingConfig


def run_centrality_based_evaluation():
    """ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€ ì‹¤í–‰"""
    print("ğŸ¯ ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print("ğŸ“Œ STEP 1: ì„ë² ë”© ì¤‘ì‹¬ì„± ë¶„ì„")
    print("ğŸ“Œ STEP 2: ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€")
    print("ğŸ¯ ëª©í‘œ: Anchor Queries Recall@10 â‰¥ 90%")
    print("=" * 60)
    
    # STEP 1: ì„ë² ë”© ì¤‘ì‹¬ì„± ë¶„ì„ ì‹¤í–‰
    print("\nğŸ” STEP 1: ì„ë² ë”© ì¤‘ì‹¬ì„± ë¶„ì„ ì‹¤í–‰ ì¤‘...")
    centrality_results = run_embedding_centrality_analysis()
    
    if centrality_results is None:
        print("âŒ ì¤‘ì‹¬ì„± ë¶„ì„ ì‹¤íŒ¨")
        return None
    
    # Anchor & Tail ì¸ë±ìŠ¤ ì¶”ì¶œ
    anchor_indices = centrality_results['sets_info']['anchor_indices']
    tail_indices = centrality_results['sets_info']['tail_indices']
    
    print(f"âœ… ì¤‘ì‹¬ì„± ë¶„ì„ ì™„ë£Œ:")
    print(f"   Anchor Set: {len(anchor_indices)}ê°œ")
    print(f"   Tail Set: {len(tail_indices)}ê°œ")
    print(f"   Anchor ì„ê³„ê°’: {centrality_results['sets_info']['anchor_threshold']:.4f}")
    
    # STEP 2: Anchor ê¸°ë°˜ í‰ê°€ ì‹¤í–‰
    print(f"\nğŸ” STEP 2: ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€ ì‹¤í–‰ ì¤‘...")
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ
    dataset_path = "C:/sample/ë¼ë²¨ë§ë°ì´í„°"
    
    # Baseline v1 ì„¤ì • (Temperature 0.1)
    config = TrainingConfig()
    config.temperature = 0.1
    config.batch_size = 16
    config.max_epochs = 8
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = FashionEncoderSystem()
        system.config = config
        
        # ë°ì´í„° ì„¤ì •
        print("ğŸ“ ë°ì´í„° ì„¤ì • ì¤‘...")
        system.setup_data(dataset_path)
        
        # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
        print("ğŸ‹ï¸ íŠ¸ë ˆì´ë„ˆ ì„¤ì • ì¤‘...")
        system.setup_trainer()
        
        # Baseline v1 ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint_path = "checkpoints/baseline_v1_best_model.pt"
        if Path(checkpoint_path).exists():
            print(f"ğŸ“¦ Baseline v1 ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")
            system.trainer.load_checkpoint(checkpoint_path)
        else:
            # ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ ì‹œë„
            checkpoint_path = "checkpoints/best_model.pt"
            if Path(checkpoint_path).exists():
                print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")
                system.trainer.load_checkpoint(checkpoint_path)
            else:
                print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ëª¨ë¸ ìƒíƒœë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
        
        # ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€ ì‹¤í–‰
        evaluator = AnchorBasedEvaluator(system, anchor_indices, tail_indices)
        evaluation_results = evaluator.run_anchor_based_evaluation()
        
        # ì¢…í•© ê²°ê³¼ ìƒì„±
        comprehensive_results = {
            'timestamp': datetime.now().isoformat(),
            'method': 'Centrality-Based Anchor Evaluation',
            'core_concept': 'ì„ë² ë”© ì¤‘ì‹¬ì„± ê¸°ë°˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ Proxy í‰ê°€',
            
            'centrality_analysis': {
                'anchor_threshold': centrality_results['sets_info']['anchor_threshold'],
                'tail_threshold': centrality_results['sets_info']['tail_threshold'],
                'anchor_categories': centrality_results['sets_info']['anchor_categories'],
                'tail_categories': centrality_results['sets_info']['tail_categories'],
                'centrality_stats': centrality_results['centrality_analysis']['statistics'],
                'distribution_analysis': centrality_results['distribution_analysis']
            },
            
            'evaluation_results': evaluation_results,
            
            'goal_achievement': evaluation_results['summary']['goal_achievement'],
            
            'key_insights': {
                'anchor_recall_10': evaluation_results['summary'].get('anchor_queries', {}).get('recall_at_10', 0),
                'all_recall_10': evaluation_results['summary'].get('all_queries', {}).get('recall_at_10', 0),
                'tail_recall_10': evaluation_results['summary'].get('tail_queries', {}).get('recall_at_10', 0),
                'improvement_vs_all': evaluation_results['summary']['goal_achievement']['improvement'],
                'target_achieved': evaluation_results['summary']['goal_achievement']['anchor_achieved']
            }
        }
        
        # ê²°ê³¼ ì €ì¥
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        results_file = results_dir / "centrality_based_evaluation_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ì¢…í•© ê²°ê³¼ ì €ì¥: {results_file}")
        
        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        print_final_summary(comprehensive_results)
        
        # ì •ë¦¬
        system.cleanup()
        
        print(f"\nâœ¨ ì¤‘ì‹¬ì„± ê¸°ë°˜ Anchor í‰ê°€ ì™„ë£Œ!")
        
        return comprehensive_results
        
    except Exception as e:
        print(f"\nâŒ í‰ê°€ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def print_final_summary(results: Dict[str, Any]):
    """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
    print(f"\n{'='*80}")
    print("ğŸ‰ ì¤‘ì‹¬ì„± ê¸°ë°˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ Proxy ì‹œìŠ¤í…œ - ìµœì¢… ê²°ê³¼")
    print(f"{'='*80}")
    
    insights = results['key_insights']
    goal = results['goal_achievement']
    
    print(f"\nğŸ¯ í•µì‹¬ ëª©í‘œ ë‹¬ì„± í˜„í™©:")
    print(f"   ëª©í‘œ: Anchor Queries Recall@10 â‰¥ 90%")
    print(f"   ì‹¤ì œ: {insights['anchor_recall_10']:.1f}%")
    print(f"   ë‹¬ì„±: {'âœ… ì„±ê³µ!' if insights['target_achieved'] else 'âŒ ë¯¸ë‹¬ì„±'}")
    
    print(f"\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:")
    print(f"   All Queries Recall@10: {insights['all_recall_10']:.1f}%")
    print(f"   Anchor Queries Recall@10: {insights['anchor_recall_10']:.1f}%")
    print(f"   Tail Queries Recall@10: {insights['tail_recall_10']:.1f}%")
    print(f"   Anchor vs All ê°œì„ : {insights['improvement_vs_all']:+.1f}%p")
    print(f"   Anchor vs Tail ê°œì„ : {insights['anchor_recall_10'] - insights['tail_recall_10']:+.1f}%p")
    
    print(f"\nğŸ§  ì¤‘ì‹¬ì„± ë¶„ì„ ê²°ê³¼:")
    centrality = results['centrality_analysis']
    print(f"   Anchor ì„ê³„ê°’: {centrality['anchor_threshold']:.4f}")
    print(f"   ì¤‘ì‹¬ì„± í‰ê· : {centrality['centrality_stats']['mean']:.4f}")
    print(f"   ì¤‘ì‹¬ì„± ë²”ìœ„: [{centrality['centrality_stats']['min']:.4f}, {centrality['centrality_stats']['max']:.4f}]")
    
    print(f"\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ Anchor ë¶„í¬:")
    for category, count in centrality['anchor_categories'].items():
        print(f"   {category}: {count}ê°œ")
    
    print(f"\nğŸ”¬ ë…¼ë¬¸/ì¡¸ì—…ì‘í’ˆ ê¸°ì—¬:")
    print(f"   âœ… íŒë§¤ ë°ì´í„° ì—†ì´ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê·¼ì‚¬ ì‹œìŠ¤í…œ êµ¬ì¶•")
    print(f"   âœ… ì„ë² ë”© ì¤‘ì‹¬ì„± ê¸°ë°˜ Proxy ê°œë… ê²€ì¦")
    print(f"   âœ… Query-aware í‰ê°€ ì‹œìŠ¤í…œ ê°œë°œ")
    print(f"   âœ… ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ì‹¬ì„± íŠ¹ì„± ë¶„ì„")
    
    if insights['target_achieved']:
        print(f"\nğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! ëª©í‘œ ë‹¬ì„±ìœ¼ë¡œ í•µì‹¬ ì•„ì´ë””ì–´ ê²€ì¦ ì„±ê³µ!")
        print(f"   'ì¤‘ì‹¬ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëŒ€ì¤‘ì ì´ë‹¤' ê°€ì„¤ ì…ì¦")
    else:
        print(f"\nğŸ“ˆ ì¶”ê°€ ìµœì í™” ë°©í–¥:")
        print(f"   - Temperature ì¶”ê°€ íŠœë‹ (0.05 ~ 0.15)")
        print(f"   - Anchor ë¹„ìœ¨ ì¡°ì • (5%, 15% í…ŒìŠ¤íŠ¸)")
        print(f"   - ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© í™œìš© (ì´ë¯¸ì§€ + JSON)")
        print(f"   - ëŒ€ì¡° í•™ìŠµ ì†ì‹¤ í•¨ìˆ˜ ê°œì„ ")


if __name__ == "__main__":
    run_centrality_based_evaluation()