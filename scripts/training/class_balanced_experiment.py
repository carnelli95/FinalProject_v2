#!/usr/bin/env python3
"""
Class-Balanced Training Experiment

í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì‹¤í—˜:
- ë ˆíŠ¸ë¡œ 9% vs ë¡œë§¨í‹± 46% vs ë¦¬ì¡°íŠ¸ 46% ë¶ˆê· í˜• í•´ê²°
- ClassBalancedSamplerë¥¼ ì‚¬ìš©í•œ í•™ìŠµ
- Baseline v1 (Temperature 0.1) ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„  ì¸¡ì •

ì˜ˆìƒ ê²°ê³¼: Top-5 ì •í™•ë„ 1-2% í–¥ìƒ (64.1% â†’ 65-66%)
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from main import FashionEncoderSystem
from utils.config import TrainingConfig


def run_class_balanced_experiment():
    """í´ë˜ìŠ¤ ê· í˜• ìƒ˜í”Œë§ ì‹¤í—˜ ì‹¤í–‰"""
    print("ğŸ”¬ Class-Balanced Training Experiment")
    print("=" * 60)
    print("ëª©í‘œ: í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ë¡œ Top-5 ì •í™•ë„ 1-2% í–¥ìƒ")
    print("ê¸°ì¤€: Baseline v1 (64.1% Top-5, Temperature 0.1)")
    print("=" * 60)
    
    # ì‹¤í—˜ ì„¤ì •
    dataset_path = "C:/sample/ë¼ë²¨ë§ë°ì´í„°"  # ì›ë˜ëŒ€ë¡œ ë³µì›
    
    # Baseline v1ê³¼ ë™ì¼í•œ ì„¤ì • ì‚¬ìš©
    config = TrainingConfig()
    config.temperature = 0.1  # Baseline v1 ìµœì  ì˜¨ë„
    config.batch_size = 16    # Baseline v1 ë°°ì¹˜ í¬ê¸°
    config.max_epochs = 8     # Baseline v1 ì—í¬í¬ ìˆ˜
    config.learning_rate = 1e-4
    
    print(f"ğŸ“Š ì‹¤í—˜ ì„¤ì •:")
    print(f"   Temperature: {config.temperature}")
    print(f"   Batch Size: {config.batch_size}")
    print(f"   Epochs: {config.max_epochs}")
    print(f"   Learning Rate: {config.learning_rate}")
    print(f"   Dataset: {dataset_path}")
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = FashionEncoderSystem()
        system.config = config
        
        # ë°ì´í„° ì„¤ì •
        print("\nğŸ“ ë°ì´í„° ì„¤ì • ì¤‘...")
        system.setup_data(dataset_path)
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        train_dataset = system.data_module.train_dataset
        class_counts = {}
        for item in train_dataset.fashion_items:
            category = item.category
            class_counts[category] = class_counts.get(category, 0) + 1
        
        total_items = sum(class_counts.values())
        print(f"\nğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬ (í•™ìŠµ ë°ì´í„°):")
        for category, count in class_counts.items():
            percentage = count / total_items * 100
            print(f"   {category}: {count}ê°œ ({percentage:.1f}%)")
        
        # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
        print("\nğŸ‹ï¸ íŠ¸ë ˆì´ë„ˆ ì„¤ì • ì¤‘...")
        checkpoint_dir = "checkpoints"
        log_dir = "logs"
        system.setup_trainer(checkpoint_dir=checkpoint_dir, log_dir=log_dir)
        
        # í´ë˜ìŠ¤ ê· í˜• ë°ì´í„°ë¡œë” ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
        print("\nâš–ï¸ í´ë˜ìŠ¤ ê· í˜• ìƒ˜í”Œë§ í™œì„±í™”...")
        train_loader = system.data_module.train_dataloader(use_class_balanced=True)
        val_loader = system.data_module.val_dataloader()
        
        print(f"   í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
        print(f"   ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
        
        # í•™ìŠµ ì‹¤í–‰
        print(f"\nğŸš€ í´ë˜ìŠ¤ ê· í˜• í•™ìŠµ ì‹œì‘...")
        print(f"   ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Contrastive Learningë§Œ ì‹¤í–‰ (Stage 2)
        results = system.trainer.train_contrastive_learning(
            train_loader=train_loader,
            val_loader=val_loader,
            num_epochs=config.max_epochs
        )
        
        # ê²°ê³¼ ë¶„ì„
        print(f"\nğŸ“Š ì‹¤í—˜ ê²°ê³¼:")
        final_metrics = results.get('final_metrics', {})
        
        top1_accuracy = final_metrics.get('top1_accuracy', 0) * 100
        top5_accuracy = final_metrics.get('top5_accuracy', 0) * 100
        mrr = final_metrics.get('mean_reciprocal_rank', 0)
        val_loss = results.get('best_val_loss', 0)
        
        print(f"   Top-1 ì •í™•ë„: {top1_accuracy:.1f}%")
        print(f"   Top-5 ì •í™•ë„: {top5_accuracy:.1f}%")
        print(f"   MRR: {mrr:.3f}")
        print(f"   ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")
        
        # Baseline v1ê³¼ ë¹„êµ
        baseline_top5 = 64.1
        baseline_top1 = 22.2
        baseline_mrr = 0.407
        
        top5_improvement = top5_accuracy - baseline_top5
        top1_improvement = top1_accuracy - baseline_top1
        mrr_improvement = mrr - baseline_mrr
        
        print(f"\nğŸ“ˆ Baseline v1 ëŒ€ë¹„ ê°œì„ :")
        print(f"   Top-5: {top5_improvement:+.1f}% ({baseline_top5:.1f}% â†’ {top5_accuracy:.1f}%)")
        print(f"   Top-1: {top1_improvement:+.1f}% ({baseline_top1:.1f}% â†’ {top1_accuracy:.1f}%)")
        print(f"   MRR: {mrr_improvement:+.3f} ({baseline_mrr:.3f} â†’ {mrr:.3f})")
        
        # ê²°ê³¼ ì €ì¥
        experiment_results = {
            "experiment_name": "Class-Balanced Training",
            "timestamp": datetime.now().isoformat(),
            "configuration": {
                "temperature": config.temperature,
                "batch_size": config.batch_size,
                "epochs": config.max_epochs,
                "learning_rate": config.learning_rate,
                "class_balanced_sampling": True,
                "dataset": dataset_path
            },
            "class_distribution": class_counts,
            "final_performance": {
                "top1_accuracy": final_metrics.get('top1_accuracy', 0),
                "top5_accuracy": final_metrics.get('top5_accuracy', 0),
                "mrr": final_metrics.get('mean_reciprocal_rank', 0),
                "validation_loss": val_loss
            },
            "baseline_comparison": {
                "baseline_v1_top5": baseline_top5,
                "baseline_v1_top1": baseline_top1,
                "baseline_v1_mrr": baseline_mrr,
                "top5_improvement": top5_improvement,
                "top1_improvement": top1_improvement,
                "mrr_improvement": mrr_improvement
            },
            "training_progression": results.get('metrics_history', {}),
            "notes": "í´ë˜ìŠ¤ ê· í˜• ìƒ˜í”Œë§ì„ í†µí•œ ë ˆíŠ¸ë¡œ í´ë˜ìŠ¤ ì–¸ë”ìƒ˜í”Œë§ ë¬¸ì œ í•´ê²° ì‹¤í—˜"
        }
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        results_file = results_dir / "class_balanced_experiment_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(experiment_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}")
        
        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        if top5_improvement >= 1.0:
            print(f"\nğŸ‰ ì‹¤í—˜ ì„±ê³µ!")
            print(f"   ëª©í‘œ ë‹¬ì„±: Top-5 ì •í™•ë„ {top5_improvement:.1f}% í–¥ìƒ")
        elif top5_improvement >= 0.5:
            print(f"\nâœ… ì‹¤í—˜ ë¶€ë¶„ ì„±ê³µ!")
            print(f"   ì†Œí­ ê°œì„ : Top-5 ì •í™•ë„ {top5_improvement:.1f}% í–¥ìƒ")
        else:
            print(f"\nâš ï¸ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ í•„ìš”")
            print(f"   ì˜ˆìƒë³´ë‹¤ ë‚®ì€ ê°œì„ : Top-5 ì •í™•ë„ {top5_improvement:.1f}% ë³€í™”")
        
        # ì •ë¦¬
        system.cleanup()
        
        print(f"\nâœ¨ í´ë˜ìŠ¤ ê· í˜• ì‹¤í—˜ ì™„ë£Œ!")
        
        return experiment_results
        
    except Exception as e:
        print(f"\nâŒ ì‹¤í—˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    run_class_balanced_experiment()