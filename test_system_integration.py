"""
Fashion JSON Encoder System Integration Test
Requirements 15-16: ë‹¨ê³„ë³„ ê°œë°œ ëª©í‘œ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦
"""

import torch
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from models.json_encoder import JSONEncoder
from models.contrastive_learner import ContrastiveLearner
from data.dataset_loader import KFashionDatasetLoader
from utils.validators import InputValidator, ModelValidator

class SystemIntegrationTester:
    """ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = {}
        self.dataset_loader = None
        self.json_encoder = None
        
    def run_all_tests(self) -> Dict[str, bool]:
        """ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ”¬ Fashion JSON Encoder ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        # Stage 1: ìƒ˜í”Œ ê²€ì¦ ë‹¨ê³„
        stage1_results = self.test_stage1_sample_validation()
        
        # Stage 2: Stage2 ëª¨ë¸ ì ê²€ ë‹¨ê³„  
        stage2_results = self.test_stage2_model_verification()
        
        # Stage 3: ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦
        checklist_results = self.test_checklist_verification()
        
        # ì „ì²´ ê²°ê³¼ ì·¨í•©
        all_results = {
            **stage1_results,
            **stage2_results, 
            **checklist_results
        }
        
        self.print_final_report(all_results)
        return all_results
    
    def test_stage1_sample_validation(self) -> Dict[str, bool]:
        """Stage 1: ìƒ˜í”Œ ê²€ì¦ ë‹¨ê³„ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ Stage 1: ìƒ˜í”Œ ê²€ì¦ ë‹¨ê³„")
        print("-" * 40)
        
        results = {}
        
        # 1.1 JSON Encoder êµ¬ì¡° ê²€ì¦
        results['json_encoder_structure'] = self.test_json_encoder_structure()
        
        # 1.2 ë°ì´í„° ë¡œë”© ê²€ì¦
        results['data_loading'] = self.test_data_loading()
        
        # 1.3 ì„ë² ë”© í’ˆì§ˆ ì´ˆê¸° í™•ì¸
        results['embedding_quality'] = self.test_embedding_quality()
        
        return results
    
    def test_stage2_model_verification(self) -> Dict[str, bool]:
        """Stage 2: Stage2 ëª¨ë¸ ì ê²€ ë‹¨ê³„ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ Stage 2: Stage2 ëª¨ë¸ ì ê²€ ë‹¨ê³„")
        print("-" * 40)
        
        results = {}
        
        # 2.1 Contrastive Learning ëª¨ë¸ ê²€ì¦
        results['contrastive_learning'] = self.test_contrastive_learning()
        
        # 2.2 ì–‘ë°©í–¥ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        results['bidirectional_recommendation'] = self.test_bidirectional_recommendation()
        
        return results
    
    def test_checklist_verification(self) -> Dict[str, bool]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦"""
        print("\nğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦")
        print("-" * 40)
        
        results = {}
        
        # 3.1 JSON Encoder Standalone Sanity Check
        results['sanity_check_pass'] = self.test_sanity_check()
        
        # 3.2 ì„ë² ë”© í’ˆì§ˆ ì ê²€
        results['embedding_quality_check'] = self.test_embedding_quality_detailed()
        
        # 3.3 ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ê²€ì¦
        results['recommendation_pipeline'] = self.test_recommendation_pipeline()
        
        return results
    
    def test_json_encoder_structure(self) -> bool:
        """JSON Encoder êµ¬ì¡° ê²€ì¦"""
        try:
            print("ğŸ—ï¸ JSON Encoder êµ¬ì¡° ê²€ì¦...")
            
            # ì–´íœ˜ í¬ê¸° ì •ì˜
            vocab_sizes = {
                'category': 10,
                'style': 50, 
                'silhouette': 20,
                'material': 30,
                'detail': 40
            }
            
            # JSON Encoder ì´ˆê¸°í™”
            self.json_encoder = JSONEncoder(
                vocab_sizes=vocab_sizes,
                embedding_dim=128,
                hidden_dim=256
            )
            
            # êµ¬ì¡° ê²€ì¦
            assert hasattr(self.json_encoder, 'category_embedding')
            assert hasattr(self.json_encoder, 'style_embedding')
            assert hasattr(self.json_encoder, 'mlp')
            
            print("âœ… JSON Encoder êµ¬ì¡° ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ JSON Encoder êµ¬ì¡° ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def test_data_loading(self) -> bool:
        """ë°ì´í„° ë¡œë”© ê²€ì¦"""
        try:
            print("ğŸ“‚ ë°ì´í„° ë¡œë”© ê²€ì¦...")
            
            # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
            self.dataset_loader = KFashionDatasetLoader(
                dataset_path="C:/sample/ë¼ë²¨ë§ë°ì´í„°",
                target_categories=['ë ˆíŠ¸ë¡œ', 'ë¡œë§¨í‹±', 'ë¦¬ì¡°íŠ¸']
            )
            
            # ë°ì´í„° ë¡œë“œ ì‹œë„
            fashion_items = self.dataset_loader.load_dataset_by_category()
            
            # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ í™•ì¸
            if len(fashion_items) > 0:
                print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(fashion_items)}ê°œ ì•„ì´í…œ")
                
                # ì–´íœ˜ êµ¬ì¶•
                vocabularies = self.dataset_loader.build_vocabularies()
                print(f"ğŸ“š ì–´íœ˜ êµ¬ì¶• ì™„ë£Œ: {len(vocabularies)}ê°œ í•„ë“œ")
                
                return True
            else:
                print("âš ï¸ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def test_embedding_quality(self) -> bool:
        """ì„ë² ë”© í’ˆì§ˆ ì´ˆê¸° í™•ì¸"""
        try:
            print("ğŸ¯ ì„ë² ë”© í’ˆì§ˆ ì´ˆê¸° í™•ì¸...")
            
            if self.json_encoder is None:
                print("âš ï¸ JSON Encoderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return False
            
            # í•©ì„± ë°°ì¹˜ ìƒì„±
            batch = self.create_synthetic_batch()
            
            # ì„ë² ë”© ìƒì„±
            with torch.no_grad():
                embeddings = self.json_encoder(batch)
            
            # ì°¨ì› ê²€ì¦
            ModelValidator.validate_output_dimension(embeddings, 512)
            
            # ì •ê·œí™” ê²€ì¦  
            ModelValidator.validate_normalization(embeddings)
            
            print("âœ… ì„ë² ë”© í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def test_contrastive_learning(self) -> bool:
        """Contrastive Learning ëª¨ë¸ ê²€ì¦"""
        try:
            print("ğŸ”„ Contrastive Learning ê²€ì¦...")
            
            if self.json_encoder is None:
                print("âš ï¸ JSON Encoderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return False
            
            # ë”ë¯¸ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (FashionCLIP ëŒ€ì‹ )
            batch_size = 4
            image_embeddings = torch.randn(batch_size, 512)
            image_embeddings = torch.nn.functional.normalize(image_embeddings, p=2, dim=-1)
            
            # JSON ë°°ì¹˜ ìƒì„±
            json_batch = self.create_synthetic_batch(batch_size)
            
            # JSON ì„ë² ë”© ìƒì„±
            with torch.no_grad():
                json_embeddings = self.json_encoder(json_batch)
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity_matrix = torch.mm(json_embeddings, image_embeddings.T)
            
            # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê²€ì¦
            assert similarity_matrix.shape == (batch_size, batch_size)
            assert torch.all(similarity_matrix >= -1.0) and torch.all(similarity_matrix <= 1.0)
            
            print("âœ… Contrastive Learning ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ Contrastive Learning ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def test_bidirectional_recommendation(self) -> bool:
        """ì–‘ë°©í–¥ ì¶”ì²œ í…ŒìŠ¤íŠ¸"""
        try:
            print("â†”ï¸ ì–‘ë°©í–¥ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
            
            # JSON â†’ ì´ë¯¸ì§€ ì¶”ì²œ ì‹œë®¬ë ˆì´ì…˜
            json_query = self.create_synthetic_batch(1)
            with torch.no_grad():
                json_embedding = self.json_encoder(json_query)
            
            # ë”ë¯¸ ì´ë¯¸ì§€ ë°ì´í„°ë² ì´ìŠ¤
            num_images = 100
            image_db = torch.randn(num_images, 512)
            image_db = torch.nn.functional.normalize(image_db, p=2, dim=-1)
            
            # ìœ ì‚¬ë„ ê³„ì‚° ë° Top-K ì„ íƒ
            similarities = torch.mm(json_embedding, image_db.T)
            top_k = 5
            top_scores, top_indices = torch.topk(similarities, k=top_k, dim=-1)
            
            # ê²°ê³¼ ê²€ì¦
            assert top_scores.shape == (1, top_k)
            assert top_indices.shape == (1, top_k)
            assert torch.all(top_scores[0] >= top_scores[0][-1])  # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í™•ì¸
            
            print(f"âœ… JSONâ†’ì´ë¯¸ì§€ ì¶”ì²œ: Top-{top_k} ì„ íƒ ì™„ë£Œ")
            
            # ì´ë¯¸ì§€ â†’ JSON ì¶”ì²œ ì‹œë®¬ë ˆì´ì…˜ (ì—­ë°©í–¥)
            image_query = torch.randn(1, 512)
            image_query = torch.nn.functional.normalize(image_query, p=2, dim=-1)
            
            # ë”ë¯¸ JSON ë°ì´í„°ë² ì´ìŠ¤ (JSON ì„ë² ë”©ë“¤)
            json_db = torch.randn(num_images, 512)
            json_db = torch.nn.functional.normalize(json_db, p=2, dim=-1)
            
            similarities = torch.mm(image_query, json_db.T)
            top_scores, top_indices = torch.topk(similarities, k=top_k, dim=-1)
            
            print(f"âœ… ì´ë¯¸ì§€â†’JSON ì¶”ì²œ: Top-{top_k} ì„ íƒ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì–‘ë°©í–¥ ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_sanity_check(self) -> bool:
        """Sanity Check ì‹¤í–‰"""
        try:
            print("ğŸ§ª Sanity Check ì‹¤í–‰...")
            
            # demo_api.pyì˜ sanity check í•¨ìˆ˜ í˜¸ì¶œ
            from demo_api import test_json_encoder_sanity_check
            result = test_json_encoder_sanity_check()
            
            if result:
                print("âœ… SANITY CHECK PASS")
                return True
            else:
                print("âŒ SANITY CHECK FAILED")
                return False
                
        except Exception as e:
            print(f"âŒ Sanity Check ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def test_embedding_quality_detailed(self) -> bool:
        """ìƒì„¸ ì„ë² ë”© í’ˆì§ˆ ì ê²€"""
        try:
            print("ğŸ” ìƒì„¸ ì„ë² ë”© í’ˆì§ˆ ì ê²€...")
            
            if self.json_encoder is None:
                return False
            
            # ë‹¤ì–‘í•œ ì…ë ¥ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
            test_cases = []
            for i in range(10):
                batch = self.create_synthetic_batch(1)
                with torch.no_grad():
                    embedding = self.json_encoder(batch)
                test_cases.append(embedding)
            
            # ì„ë² ë”© ë‹¤ì–‘ì„± ê²€ì¦
            all_embeddings = torch.cat(test_cases, dim=0)  # [10, 512]
            
            # í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë„ˆë¬´ ìœ ì‚¬í•˜ë©´ ì•ˆë¨)
            similarity_matrix = torch.mm(all_embeddings, all_embeddings.T)
            # ëŒ€ê°ì„  ì œì™¸í•œ í‰ê·  ìœ ì‚¬ë„
            mask = ~torch.eye(10, dtype=torch.bool)
            avg_similarity = similarity_matrix[mask].mean().item()
            
            # ì„ë² ë”©ì´ ë„ˆë¬´ ìœ ì‚¬í•˜ì§€ ì•Šì€ì§€ í™•ì¸ (ë‹¤ì–‘ì„± í™•ë³´)
            if avg_similarity < 0.9:  # 90% ë¯¸ë§Œì˜ í‰ê·  ìœ ì‚¬ë„
                print(f"âœ… ì„ë² ë”© ë‹¤ì–‘ì„± í™•ë³´: í‰ê·  ìœ ì‚¬ë„ {avg_similarity:.4f}")
                return True
            else:
                print(f"âš ï¸ ì„ë² ë”© ë‹¤ì–‘ì„± ë¶€ì¡±: í‰ê·  ìœ ì‚¬ë„ {avg_similarity:.4f}")
                return False
                
        except Exception as e:
            print(f"âŒ ìƒì„¸ ì„ë² ë”© í’ˆì§ˆ ì ê²€ ì‹¤íŒ¨: {e}")
            return False
    
    def test_recommendation_pipeline(self) -> bool:
        """ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ê²€ì¦"""
        try:
            print("ğŸ”„ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ê²€ì¦...")
            
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜
            # 1. ì…ë ¥ ì²˜ë¦¬
            style_input = {
                "category": "ìƒì˜",
                "style": ["ë ˆíŠ¸ë¡œ", "ìºì£¼ì–¼"],
                "silhouette": "ì˜¤ë²„ì‚¬ì´ì¦ˆ",
                "material": ["ë‹ˆíŠ¸"],
                "detail": ["ë¼ìš´ë“œë„¥"]
            }
            
            # 2. JSON ì²˜ë¦¬ (ì‹¤ì œ ë°ì´í„° ë¡œë” ì‚¬ìš©)
            if self.dataset_loader and self.dataset_loader._vocabularies_built:
                try:
                    processed_batch = self.dataset_loader.process_json_for_inference(style_input)
                    
                    # 3. ì„ë² ë”© ìƒì„±
                    with torch.no_grad():
                        query_embedding = self.json_encoder(processed_batch)
                    
                    # 4. ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
                    db_size = 50
                    db_embeddings = torch.randn(db_size, 512)
                    db_embeddings = torch.nn.functional.normalize(db_embeddings, p=2, dim=-1)
                    
                    similarities = torch.mm(query_embedding, db_embeddings.T)
                    top_5_scores, top_5_indices = torch.topk(similarities, k=5, dim=-1)
                    
                    print("âœ… ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ")
                    return True
                    
                except Exception as e:
                    print(f"âš ï¸ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨, í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´: {e}")
            
            # í•©ì„± ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
            synthetic_batch = self.create_synthetic_batch(1)
            with torch.no_grad():
                embedding = self.json_encoder(synthetic_batch)
            
            print("âœ… í•©ì„± ë°ì´í„° ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def create_synthetic_batch(self, batch_size: int = 4) -> Dict[str, torch.Tensor]:
        """í•©ì„± ë°°ì¹˜ ë°ì´í„° ìƒì„±"""
        return {
            'category': torch.randint(1, 10, (batch_size,)),
            'style': torch.randint(1, 50, (batch_size, 4)),
            'silhouette': torch.randint(1, 20, (batch_size,)),
            'material': torch.randint(1, 30, (batch_size, 3)),
            'detail': torch.randint(1, 40, (batch_size, 5)),
            'style_mask': torch.ones(batch_size, 4, dtype=torch.long),
            'material_mask': torch.ones(batch_size, 3, dtype=torch.long),
            'detail_mask': torch.ones(batch_size, 5, dtype=torch.long)
        }
    
    def print_final_report(self, results: Dict[str, bool]):
        """ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ìµœì¢… ê²°ê³¼")
        print("=" * 60)
        
        passed_tests = sum(results.values())
        total_tests = len(results)
        success_rate = (passed_tests / total_tests) * 100
        
        print(f"ğŸ¯ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({passed_tests}/{total_tests})")
        print("\nğŸ“‹ ì„¸ë¶€ ê²°ê³¼:")
        
        for test_name, passed in results.items():
            status = "âœ… PASS" if passed else "âŒ FAIL"
            print(f"   {test_name}: {status}")
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ìš”ì•½
        print(f"\nğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒíƒœ:")
        
        stage_checks = {
            "JSON Encoder êµ¬ì¡° ê²€ì¦": results.get('json_encoder_structure', False),
            "ë°ì´í„° ë¡œë”©": results.get('data_loading', False), 
            "ì„ë² ë”© í’ˆì§ˆ í™•ì¸": results.get('embedding_quality', False),
            "Contrastive Learning": results.get('contrastive_learning', False),
            "ì–‘ë°©í–¥ ì¶”ì²œ": results.get('bidirectional_recommendation', False),
            "Sanity Check": results.get('sanity_check_pass', False),
            "ì¶”ì²œ íŒŒì´í”„ë¼ì¸": results.get('recommendation_pipeline', False)
        }
        
        for check_name, status in stage_checks.items():
            icon = "â˜‘ï¸" if status else "â˜"
            print(f"   {icon} {check_name}")
        
        # ìµœì¢… íŒì •
        critical_tests = ['json_encoder_structure', 'embedding_quality', 'sanity_check_pass']
        critical_passed = all(results.get(test, False) for test in critical_tests)
        
        if critical_passed and success_rate >= 80:
            print(f"\nğŸ‰ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print("   ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ë©° ì‹¤ìš©í™” ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif critical_passed:
            print(f"\nâš ï¸ ì‹œìŠ¤í…œ ê¸°ë³¸ ê¸°ëŠ¥ ì •ìƒ, ì¼ë¶€ ê³ ê¸‰ ê¸°ëŠ¥ ê°œì„  í•„ìš”")
            print("   í•µì‹¬ ê¸°ëŠ¥ì€ ì‘ë™í•˜ì§€ë§Œ ì¶”ê°€ ê°œë°œì´ ê¶Œì¥ë©ë‹ˆë‹¤.")
        else:
            print(f"\nâŒ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            print("   í•µì‹¬ ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆì–´ ì¶”ê°€ ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ê²°ê³¼ ì €ì¥
        self.save_integration_test_results(results, success_rate)
    
    def save_integration_test_results(self, results: Dict[str, bool], success_rate: float):
        """í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        Path("temp_logs").mkdir(exist_ok=True)
        
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "success_rate": success_rate,
            "total_tests": len(results),
            "passed_tests": sum(results.values()),
            "detailed_results": results,
            "status": "PASS" if success_rate >= 80 else "PARTIAL" if success_rate >= 60 else "FAIL"
        }
        
        with open("temp_logs/integration_test_results.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: temp_logs/integration_test_results.json")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = SystemIntegrationTester()
    results = tester.run_all_tests()
    return results

if __name__ == "__main__":
    main()